{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24179,
     "status": "ok",
     "timestamp": 1757097381226,
     "user": {
      "displayName": "SUDIP KUNDU",
      "userId": "08169988545995913889"
     },
     "user_tz": -330
    },
    "id": "SRlgQzUqO11P",
    "outputId": "7091b4c3-edbf-49fa-8b55-36bc6c714ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/medical-image-cnn\n",
      "SRC contents: ['classification', 'segmentation', 'detection', 'utils.py', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# 1. Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Change directory to project root\n",
    "project_path = \"/content/drive/MyDrive/medical-image-cnn\"\n",
    "%cd $project_path\n",
    "\n",
    "# 3. Add project root to Python path\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "# 4. Ensure __init__.py files exist in src/ packages\n",
    "folders = [\n",
    "    \"src\",\n",
    "    \"src/classification\",\n",
    "    \"src/segmentation\",\n",
    "    \"src/detection\"\n",
    "]\n",
    "for folder in folders:\n",
    "    init_file = os.path.join(folder, \"__init__.py\")\n",
    "    if not os.path.exists(init_file):\n",
    "        with open(init_file, \"w\") as f:\n",
    "            f.write(\"# init\\n\")\n",
    "        print(f\"Created: {init_file}\")\n",
    "\n",
    "# 5. Check structure\n",
    "print(\"SRC contents:\", os.listdir(os.path.join(project_path, \"src\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5950,
     "status": "ok",
     "timestamp": 1757097081630,
     "user": {
      "displayName": "SUDIP KUNDU",
      "userId": "08169988545995913889"
     },
     "user_tz": -330
    },
    "id": "cW_aH8Qojzg1",
    "outputId": "867d30cb-993b-4629-cea1-d3bea4729067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras matplotlib seaborn scikit-learn opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8561,
     "status": "ok",
     "timestamp": 1757097097338,
     "user": {
      "displayName": "SUDIP KUNDU",
      "userId": "08169988545995913889"
     },
     "user_tz": -330
    },
    "id": "xTu7XJ0JIbZV",
    "outputId": "eea45cb8-a9d2-4420-c428-dc15330944d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13888 images belonging to 4 classes.\n",
      "Found 3470 images belonging to 4 classes.\n",
      "Found 4333 images belonging to 4 classes.\n",
      "Classes: {'glioma_tumor': 0, 'meningioma_tumor': 1, 'normal': 2, 'pituitary_tumor': 3}\n",
      "Filtered test set to 4333 images with classes from training set.\n",
      "Number of classes for model: 4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from src.classification.data_loader import get_classification_generators\n",
    "from src.classification.model_builder import build_mobilenet_classifier\n",
    "from src.utils import plot_training\n",
    "import numpy as np # Added numpy import\n",
    "\n",
    "# Load Data\n",
    "# Point data_dir to the root of the dataset where train, val, and test folders are located\n",
    "data_dir = \"/content/drive/MyDrive/medical-image-cnn/datasets/brain_mri\"\n",
    "img_size = (128,128)   # smaller images = faster\n",
    "batch_size = 16\n",
    "\n",
    "train_gen, val_gen, test_gen = get_classification_generators(\n",
    "    data_dir=data_dir,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Get the classes from the training generator\n",
    "train_classes = list(train_gen.class_indices.keys())\n",
    "num_classes = len(train_classes)\n",
    "print(\"Classes:\", train_gen.class_indices)\n",
    "\n",
    "# Filter test_gen to only include classes present in train_gen\n",
    "# This assumes get_classification_generators returns a DirectoryIterator\n",
    "if hasattr(test_gen, 'classes'):\n",
    "    # Recreate class_indices for the test set based on available classes\n",
    "    test_class_indices = {cls: i for i, cls in enumerate(sorted(list(set([test_gen.filenames[i].split('/')[0] for i in range(len(test_gen.filenames))]))))}\n",
    "\n",
    "    test_indices = [i for i in range(len(test_gen.filenames)) if test_gen.filenames[i].split('/')[0] in train_classes]\n",
    "\n",
    "    # Create a new generator with filtered indices\n",
    "    from tensorflow.keras.utils import Sequence\n",
    "    class FilteredTestDataGenerator(Sequence):\n",
    "        def __init__(self, original_generator, indices, class_indices):\n",
    "            self.generator = original_generator\n",
    "            self.indices = indices\n",
    "            self.batch_size = original_generator.batch_size\n",
    "            self.class_indices = class_indices # Use the filtered class indices\n",
    "            self.classes = np.array([self.class_indices[original_generator.filenames[i].split('/')[0]] for i in indices]) # Update classes attribute\n",
    "\n",
    "        def __len__(self):\n",
    "            return int(np.ceil(len(self.indices) / self.batch_size))\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            batch_indices_in_original = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            # Get the batch using the original generator's method\n",
    "            # This might require accessing protected members, adjust if necessary based on the actual generator implementation\n",
    "            batch_x, batch_y_original = self.generator._get_batches_of_transformed_samples(batch_indices_in_original)\n",
    "\n",
    "            # If original_generator yields one-hot encoded labels, convert back to integer\n",
    "            if batch_y_original.ndim > 1:\n",
    "                batch_y_original = np.argmax(batch_y_original, axis=1)\n",
    "\n",
    "            # Map original class indices to filtered class indices\n",
    "            batch_y_filtered = np.array([self.class_indices[list(self.generator.class_indices.keys())[original_label]] for original_label in batch_y_original])\n",
    "\n",
    "            # One-hot encode filtered labels if needed by the model\n",
    "            # Assuming the model expects one-hot encoding\n",
    "            num_filtered_classes = len(self.class_indices)\n",
    "            batch_y_one_hot = np.zeros((len(batch_y_filtered), num_filtered_classes))\n",
    "            batch_y_one_hot[np.arange(len(batch_y_filtered)), batch_y_filtered] = 1\n",
    "\n",
    "            return batch_x, batch_y_one_hot\n",
    "\n",
    "\n",
    "    # Create class_indices for the filtered test set\n",
    "    filtered_test_class_labels = sorted(list(set([test_gen.filenames[i].split('/')[0] for i in test_indices])))\n",
    "    filtered_test_class_indices = {cls: i for i, cls in enumerate(filtered_test_class_labels)}\n",
    "\n",
    "\n",
    "    test_gen = FilteredTestDataGenerator(test_gen, test_indices, filtered_test_class_indices)\n",
    "    print(f\"Filtered test set to {len(test_indices)} images with classes from training set.\")\n",
    "    # Update num_classes to reflect the number of classes in the training set\n",
    "    num_classes = len(train_classes)\n",
    "    print(f\"Number of classes for model: {num_classes}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
